{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'CLIP'...\n",
      "remote: Enumerating objects: 256, done.\u001b[K\n",
      "remote: Total 256 (delta 0), reused 0 (delta 0), pack-reused 256\u001b[K\n",
      "Receiving objects: 100% (256/256), 8.93 MiB | 506.00 KiB/s, done.\n",
      "Resolving deltas: 100% (133/133), done.\n",
      "Updating files: 100% (22/22), done.\n",
      "Cloning into 'taming-transformers'...\n",
      "remote: Enumerating objects: 1342, done.\u001b[K\n",
      "remote: Counting objects: 100% (2/2), done.\u001b[K\n",
      "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
      "error: RPC failed; curl 92 HTTP/2 stream 0 was not closed cleanly: CANCEL (err 8)\n",
      "error: 4253 bytes of body are still expected\n",
      "fetch-pack: unexpected disconnect while reading sideband packet\n",
      "fatal: early EOF\n",
      "fatal: fetch-pack: invalid index-pack output\n"
     ]
    }
   ],
   "source": [
    "# !git clone https://github.com/openai/CLIP.git\n",
    "\n",
    "\n",
    "# !git clone https://github.com/CompVis/taming-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ftfy in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (6.2.0)\n",
      "Requirement already satisfied: regex in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (2022.7.9)\n",
      "Requirement already satisfied: tqdm in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (4.65.0)\n",
      "Requirement already satisfied: omegaconf==2.0.0 in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (2.0.0)\n",
      "Requirement already satisfied: pytorch-lightning==1.0.8 in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (1.0.8)\n",
      "Requirement already satisfied: PyYAML in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (from omegaconf==2.0.0) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (from omegaconf==2.0.0) (4.4.0)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (from pytorch-lightning==1.0.8) (2.17.0)\n",
      "Requirement already satisfied: numpy>=1.16.4 in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (from pytorch-lightning==1.0.8) (1.25.2)\n",
      "Requirement already satisfied: fsspec>=0.8.0 in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (from pytorch-lightning==1.0.8) (2024.6.1)\n",
      "Requirement already satisfied: torch>=1.3 in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (from pytorch-lightning==1.0.8) (2.0.1)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (from pytorch-lightning==1.0.8) (4.65.0)\n",
      "Requirement already satisfied: future>=0.17.1 in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (from pytorch-lightning==1.0.8) (0.18.3)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (2.2.3)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (2.1.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (58.0.4)\n",
      "Requirement already satisfied: six>1.9 in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (1.16.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (3.6)\n",
      "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (4.25.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (0.7.2)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (1.64.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.0.8) (6.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.0.8) (3.11.0)\n",
      "Requirement already satisfied: filelock in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (from torch>=1.3->pytorch-lightning==1.0.8) (3.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (from torch>=1.3->pytorch-lightning==1.0.8) (1.11.1)\n",
      "Requirement already satisfied: networkx in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (from torch>=1.3->pytorch-lightning==1.0.8) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (from torch>=1.3->pytorch-lightning==1.0.8) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard>=2.2.0->pytorch-lightning==1.0.8) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (from sympy->torch>=1.3->pytorch-lightning==1.0.8) (1.3.0)\n",
      "\u001b[33mWARNING: Skipping torchtext as it is not installed.\u001b[0m\n",
      "Requirement already satisfied: einops in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (0.8.0)\n"
     ]
    }
   ],
   "source": [
    "# Some More installs\n",
    "\n",
    "!pip install --no-deps ftfy regex tqdm\n",
    "!pip install omegaconf==2.0.0 pytorch-lightning==1.0.8\n",
    "!pip uninstall torchtext --yes\n",
    "!pip install einops\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imageio in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (2.34.2)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (from imageio) (9.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (from imageio) (1.25.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (3.9.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (from matplotlib) (1.25.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (from matplotlib) (4.53.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (from matplotlib) (6.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "import torch\n",
    "!pip3 install imageio\n",
    "import os, tqdm, imageio, pdb, math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# viz imports\n",
    "!pip3 install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. We need intermediate results to be shown for each iteration\n",
    "# 2. normalise and bring (-1, 1) to (0, 0.5)\n",
    "# 3. optimisation and reguralisation params\n",
    "\n",
    "\n",
    "def show_tensor(tensor):\n",
    "    img = tensor.clone()\n",
    "    img = img.mul(255) # (0, 1) before for faster and stable training\n",
    "    img = img.cpu().numpy().transpose(1, 2, 0)\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "def norm(x):\n",
    "    return (x.clip(-1, 1) + 1)/2 # 1st clip within -1 to 1 then (0, 2) by adding 1, then (0, 1)\n",
    "\n",
    "# optimisation params\n",
    "wd = 0.1 # recall this is generalisation param, where penalise larger weights\n",
    "# Loss = Original_Loss + lambda * W^2\n",
    "# Larger weights basically memorise the training data. How?\n",
    "# Larger weights make model highly sensitive to smaller changes in training data\n",
    "# resulting in capturing the noise as well on top of capturing the patterns\n",
    "# Smaller weights means => Less variance in model's predictions => more stable across datasets\n",
    "# => Less sensitive to noise\n",
    "# Penalising higher weights makes the model find a sweet-spot between good accuracy \n",
    "# and more generalisation\n",
    "lr = 0.5\n",
    "batch_size = 1\n",
    "total_iterations = 100 # good starting point\n",
    "noise_factor = 0.1\n",
    "\n",
    "# image shapes\n",
    "image_shape = [225, 400, 3]\n",
    "height, width, channels = image_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 338M/338M [02:55<00:00, 2.02MiB/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'VisionTransformer' object has no attribute 'image_resolution'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m clipmodel, _ \u001b[38;5;241m=\u001b[39m clip\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mViT-B/32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# input image shape?\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m img_shape \u001b[38;5;241m=\u001b[39m \u001b[43mclipmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisual\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_resolution\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m( img_shape )\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'VisionTransformer' object has no attribute 'image_resolution'"
     ]
    }
   ],
   "source": [
    "from CLIP import clip\n",
    "\n",
    "# Available models for CLIP\n",
    "# print( clip.available_models() ) # ['RN50', 'RN101', 'RN50x4', 'RN50x16', 'RN50x64', 'ViT-B/32', 'ViT-B/16', 'ViT-L/14', 'ViT-L/14@336px']\n",
    "\n",
    "clipmodel, _ = clip.load('ViT-B/32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224\n"
     ]
    }
   ],
   "source": [
    "# input image shape?\n",
    "img_shape = clipmodel.visual.input_resolution\n",
    "print( img_shape ) # 224 -> n patches of (3, 224, 224) -> After CLIP -> img encoding -> n x 512\n",
    "\n",
    "# set to eval as already trained\n",
    "clipmodel.eval()\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "# emprt cache\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
